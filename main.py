## chatbot
import re
import os
import sys
import streamlit as st
from streamlit_mic_recorder import mic_recorder, speech_to_text
from openai import OpenAI
from gtts import gTTS
import base64
import tempfile
from io import BytesIO
# from pydub import AudioSegment
# from pydub.playback import play
# from pydub import effects
# from dotenv import load_dotenv
# load_dotenv(verbose=True)
from main_prompts import get_system_prompt

st.title("ğŸ’¬ ë‰´ìŠ¤ íë ˆì´í„°")

# keywords ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
if "keywords" not in st.session_state:
    st.session_state["keywords"] = []


def autoplay_audio(file_path: str):
    with open(file_path, "rb") as f:
        data = f.read()
        b64 = base64.b64encode(data).decode()
        md = f"""
            <audio controls autoplay="true">
            <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
            </audio>
            """
        st.markdown(
            md,
            unsafe_allow_html=True,
        )



## í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
import re

class Extractor:
    def __init__(self):
        self.stored_index = None
    def extract_keyword(self, text):
    
        pattern = re.compile(r"(?:ì˜¤ëŠ˜ì˜\s*|ì˜¤ëŠ˜\s*)?(.*?)\s*ë‰´ìŠ¤")
        match = pattern.search(text)
        
        keyword = None
        index = None
        
        if match:
            keyword = match.group(1).strip()
            if keyword.endswith("ë²ˆì§¸"):
                index_map = {
                    'ì²«': 0, 'ë‘': 1, 'ì„¸': 2, 'ë„¤': 3, 'ë‹¤ì„¯': 4,
                    'ì—¬ì„¯': 5, 'ì¼ê³±': 6, 'ì—¬ëŸ': 7, 'ì•„í™‰': 8, 'ì—´': 9
                }
                prefix = keyword.split()[0]
                index = index_map.get(prefix, None)
                self.stored_index = index  
            if "ë‹¤ìŒ" in text and self.stored_index is not None:
                self.stored_index += 1  
                index = self.stored_index
    
        return keyword, index
    
extract = Extractor()


## ë‹µë³€ ìƒì„± í•¨ìˆ˜
def complete(questions, prompt):
    res =  client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
                {"role": "system", "content": prompt},
                {"role":"user", "content": f"{questions}"}
            ],
    )
    response = res.choices[0].message.content
    return response

openai_api_key = st.secrets.OPENAI_API_KEY
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "Start recording ë²„íŠ¼ì„ ëˆŒëŸ¬ ì§ˆë¬¸í•´ì£¼ì„¸ìš”"}]

text = speech_to_text(language='ko', use_container_width=True, just_once=True, key='STT')

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if text:
    keyword, index = extract.extract_keyword(text)
    stored_index = extract.stored_index
    print(stored_index) 
    # st.write(f"ì£¼ì œ: {keyword}")
    # st.write(f"ì¸ë±ìŠ¤: {index}")
    st.session_state["keywords"].append(keyword)

    st.session_state["keywords"][-1] = st.session_state["keywords"][-1].replace('ì¸ê³µì§€ëŠ¥', 'AI')
    # st.write(f"í˜„ì¬ í‚¤ì›Œë“œ ëª©ë¡: {st.session_state['keywords']}")

    
    if keyword not in ['AI', 'ë¶€ë™ì‚°']:
        latest_keyword = st.session_state["keywords"][-2]
    else:
        latest_keyword = st.session_state["keywords"][-1]

    meta = f"""
        SELECT
            "ì œëª©",
            "ë‚´ìš©",
            "ìš”ì•½"
        FROM NEWS.CRAWLING_DATA.NAVER_NEWS
        WHERE "ê²€ìƒ‰ì–´"='{latest_keyword}'
        LIMIT 10;
    """

    


    client = OpenAI(api_key=openai_api_key)

    st.session_state.messages.append({"role": "user", "content": text})
    st.chat_message("user").write(text)

    msg = complete(text, get_system_prompt(meta))
    
    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.chat_message("assistant").write(msg)
    conn = st.connection("snowflake")
    df = conn.query(meta)
    st.dataframe(df)
    
    if msg:
        sound_file = BytesIO()
        tts = gTTS(text=msg, lang='ko', slow=False)
        tts.write_to_fp(sound_file)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as temp_file:
            temp_file.write(sound_file.getvalue())
            temp_file_path = temp_file.name

        autoplay_audio(temp_file_path)
        os.remove(temp_file_path)
        if not st.session_state["keywords"][-1] in ['AI','ë¶€ë™ì‚°']:
            st.session_state["keywords"].pop()

        ## ì†ë„ ì¡°ì ˆ
        # sound_file.seek(0)
        # say = AudioSegment.from_file(sound_file, format="mp3")
        # say_speed = say.speedup(
        # playback_speed=1.25, chunk_size=150, crossfade=25)
        # play(say_speed)
